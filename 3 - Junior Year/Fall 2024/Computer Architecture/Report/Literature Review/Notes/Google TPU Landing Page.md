Date: 20th November 2024
Date Modified: 20th November 2024
File Folder: Notes
## Publication Information

**Database:**  Google Cloud

**DOI**:  https://cloud.google.com/tpu

**Authors**: Google

**Publication Year**: 2024

**Country of Study**: USA

**Tags**: #tpu #google #introduction

```ad-abstract
title: Abstract
collapse: open
Cloud TPUs optimize performance and cost for all AI workloads, from training to inference. Using world-class data center infrastructure, TPUs offer high reliability, availability, and security.
```

**Used inâ€¦**: Introduction/Market

**Embed to Paper**: ![[Tensor Processing Units (TPUs) _ Google Cloud.pdf]]
## Summary

### Overview

#### What is a TPU?

Custom-designed AI accelerators, which are optimized for training and inference of large AI models. 

#### TPU vs GPU?

A GPU is specialized processor for computer graphics. Their parallel structure makes them ideal for algorithms that process large blocks of data, like AI workloads

TPU is an ASIC designed by Google for neural networks. Contain MXU and proprietary interconnect topology which makes them ideal for accelerating AI training and interference.
