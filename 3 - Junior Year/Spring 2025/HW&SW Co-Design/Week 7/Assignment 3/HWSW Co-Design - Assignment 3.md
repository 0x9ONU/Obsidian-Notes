Date: 6th March 2025
Date Modified: 6th March 2025
File Folder: Assignment 3
#hwsw

```ad-abstract
title: Author Information
collapse: open

**Name**: Ethan Berei
**Date**: March 7th, 2025
**Content**: Invetigating Multi-Core Scheduling in Real-Time Systems

```

# Introduction

When it comes to operating systems and their list of responsibilities, one of the most important aspects is how they schedule processes on a processor to maximize the CPU’s utilization while keeping ahead of deadlines to ensure real-time operations in the best case. Traditionally, to solve how processes hit their deadlines on a single-core CPU, two primary methods were devised: *Rate Monotonic Scheduling (RMS)* and *Earliest Deadline First (EDF)*. In RMS, each process that is in queue for the CPU is given a priority from most important to least important. The OS chooses a process that has the highest priority and runs through it’s entirety. Once the process finishes, the OS chooses the next process with the highest priority and continues this until the end of it’s hyperperiod. EDF builds off of this concept by giving processes priority based on how fast their next deadline is approaching. On each clock cycle, the OS determines which process needed to run next in order to hit it’s deadline and runs the most urgent process. Both of these methods are typically considered plenty when it comes to single-core real-time systems and allows the CPU to efficiently reach a high amount of utilization while running relatively simple algorithms [1].

However, as the computing space exploded throughout the years, the introduction of the multi-core system became a mainstay. As the name suggests, a CPU die now consists of multiple processors that work in parallel with each other to complete tasks much faster. There was a lot of problems when it came to implementing them though. On of the primary hurdles came from the need for another form of scheduling techniques as RMS and EDF failed to work effectively on these multi-core systems. In particular, they faced problems when it came to migrating tasks between the different courses, how to evenly spread the workload over each core, did not know how to communicate each core with one another, could not uphold across larger core counts, and had troubles sharing resources with each core. Therefore, new techniques needed to be discovered in order to effectively use new multi-core CPUs [2].

In this report, the downfalls of RMS and EDF in multi-core systems will be outlined in detail. Then, multiple alternative implementations for schedulers are presented with their own pros and cons. Then, three real-life scenarios are given and how they impacted the performance of CPUs over RMS and EDF.

# RMS and EDF: Not Ideal for Multi-Core

When it comes to the use of both RMS and EDF in multi-core processors, they have been considered obsolete in such systems as they fail to hit to provide real-time guarantees in multi-core systems. The main issues comes from how multi-core systems have to equally split across multiple sections in order to have successful usage of the processor while also being able to hit deadlines [3]. Specifically, they fail in task mitigation, load balancing, managing synchronization overhead, scalability, sharing resources, handling dynamic workload overhead, and improving energy efficiency.

*Task migration* is a new challenge that is brought to the table when switching from single-core processors to multi-core processors. Specifically, to effectively use each core, task migration allows a process to move from one core to another to either reduce the workload on a single CPU core or meet processing deadlines. *Load balancing* techniques take advantage of multi-core systems by equally distributing workloads across multiple cores by using task migration whenever it is necessary. In more modern task scheduling algorithms, these two concepts work hand-in-hand to improve the CPU’s utilization. However, RMS and EDF often succumb to the overloading demands placed on a multi-core chip, which can lead to the **Domino Effect**. If a CPU is overloaded, there is a high chance that a deadline is missed, which can further lead to subsequent tasks to miss their deadline and make the operating system crash. Implementing task migration to RMS or EDF seems like an easy choice, but both algorithms do not have the process natively in them. This approach can lead to increased complexity and switching overhead, which can introduce latency [3]. When considering heavier algorithms such as dynamic load balancing, it can introduce so much overhead that it might not be able to meet real-time deadlines [4-5]. This is even further be affected by global scheduling, which allows any task to migrate between cores freely. The overhead, which can be caused by cache misses and cores having to communicate with each other, can also hurt real-time performance if implemented on top of RMS or EDF [6]. Due to both methods being designed specifically designed with single-core processors in mind, they both lack modern task mitigation protocols in their design, which makes increased overhead and latency a necessity to keep up with other task scheduling algorithms.

Allocating *synchronization overhead* is a necessity in modern task scheduling methodologies to ensure real-time operation. Specifically, the scheduler must be aware of any additional time or resources that are needed to ensure that communication between different processes on multiple cores runs smoothly. For example, a global task queue is necessary when using a global scheduling system with task mitigation in order to make sure each task is executed in the correct order across each core. This solution requires a high amount of synchronization across each core, which can lead to bottlenecks and increased latency if not properly addressed [4-6]. RMS and EDF do not consider synchronization overhead, as they were designed without the need for the overhead to be considered. This means that, much like task migration, a custom solution is needed to deal with synchronization overhead for both RMS and EDF. This is not only resource-intensive to develop such a solution, implementing such an overhead on top of RMS and EDF could lead to latency delays and even jeopardize real-time operations if not created properly.

A system is *scalable* when it is able to utilize it’s multiple cores to handle an increasing workload without performance degradation. Unfortunately, RMS and EDF do not scale well past single core workloads due to the fact that they lack important scaling mechanisms such as task mitigation out of the box [3]. This is especially apparent when the amount of processors increase. RMS and EDF, even with the necessary modifications, will always begin to degrade over other schedulers as it will always fail to hit scalability guarantees as the number and complexity of the cores increase [5-6].

The shared resource contention around a multi-core system is a problem with multi-core systems that cannot be solved by RMS and EDF easily. Multiple different processes might compete for different resources, like memory or I/O devices, and can lead to **priority inversion** or **deadlocks**. Priority inversion occurs when a process of lower priority might try to keep it’s access to a resource that a higher priority needs, leading to problems with deadlines [7]. Deadlocks can then further happen where two or more processes are left hogging each other’s resources until they are left at a standstill indefinitely [6]. In typical RMS and EDF implementations, the scheduler does not take either of these situations into account as single-core systems cannot run into a shared resource problem. Therefore, RMS and EDF might not be able to hit real-time system deadlines as either priority inversion or deadlocks can lead to delays in processes running [5].

There are also concerns when it comes to real-time systems that utilize either aperiodic or sporadic tasks in dynamic workloads. In this case, each task might not have a set deadline before it gets placed on the process, can change their deadline suddenly, and might not line up with the traditional clocks that RMS and EDF and designed to work with. If a real-time system decides to utilize dynamic workflows while also trying to use these more simple task schedulers, both increase overhead and suboptimal performance should be expected as tasks with varying execution times can reduce the efficiency of them [4-6].

RMS and EDF typically have problems when it comes to upkeeping the energy efficiency of a processor. Both forms of task schedulers do not consider power consumption when it comes to their algorithm. Allocating resources and processes improperly can lead to poor utilization and higher energy costs by the CPU. RMS and EDF struggle to minimize energy consumption since they do not consider energy usage as a consideration when they go to schedule tasks. They only typically worry about deadlines and priorities of tasks [4].

Each of these issues in combination can lead to RMS and EDF to miss real-time guarantees for multi-core systems. The additions that are necessary for task migration, synchronization, load imbalance, aperiodic tasks, and energy efficiency concerns can all lead to a combined overhead that makes RMS and EDF have significant delays. Additionally, cache misses, inter-core communication, global scheduling problems, and failing to balance loads across cores can cause many problems overtime. Overall, RMS and EDF do not cut it when it comes to multi-core systems. Other scheduling approaches and improved handling of dynamic workloads are necessary to ensure real-time guarantees in multi-core systems [3-6].

# Alternative Scheduling Techniques

To overcome the challenges faced by multi-core solutions, RMS and standard EDF are often put aside for other algorithms that are better suited to complete the job. The alternative scheduling variations are either extensions of RMS and EDF, or are built from the ground up to consider problems such as task migration and scalability. Five different techniques are typically used: global earliest deadline first (G-EDF), hybrid scheduling, slack stealing, fair scheduling, and cluster scheduling [8-9].

## Global Earliest Deadline First (G-EDF)

G-EDF is one of the most well-known algorithms used for multi-core systems. As the name suggests, this scheduling technique builds off of EDF in an attempt to expand the uniprocessor scheduler into a multiprocessing scenario. Much like EDF, Global-EDF will prioritize tasks based on their deadlines dynamically; however, it will always move tasks to execute on the more available processor core. In order to hit these scheduling goals, G-EDF utilizes three main changes in it’s priority points (PP), job-level stat priority (JLSP), task mitigation, reduction of overhead.

Priorities points are the primary method of how priorities are assigned to tasks in G-EDF. Each job is given a priority point, which will tell the scheduler which task to put next in line. This is much like how EDF schedules tasks as it often give the highest priority to the task with the nearest deadline; however, G-EDF can consider multiple cores in systems and give a process a different core over another one if it has the highest priority. G-EDF also takes advantage of job-level static priority (JLSP) in providing real-time synchronization. When assigning a tasks, it fixes it’s priority during execution and makes sure the priority is reduced once execution is complete. This allows the algorithm to effectively give a task a priority on a core with the hopes that their deadline is successfully made across each core. To work on multi-core systems, G-EDF is given a simple form of task mitigation which allows for higher priority processes to move to more open cores. It might be simple, but it provides a fast and easy way to move tasks to different cores without much overhead. Another attractive use case of G-EDF is it’s relatively low overhead when compared to other multi-processor task schedulers. This allows the scheduler to be more agile than RMS, EDF, and other more modern task schedulers and potentially make more preemptions and migrations when compared to it’s competition. Figure 1 below illustrates a simplified diagram of G-EDF:

![[nteractions-of-G-EDF-scheduler-with-other-Trampolines-components-The-scheduling.png | center]]

<center> <b> Figure 1: </b> Basic Overview of How G-EDF Schedules Tasks [10] </center>

However, not every scheduler is perfect and G-EDF is not the exception. Even though it fixes many of the multi-core problems that came with EDF, it still is inherently flawed. It still faces problem as it is still difficult to scale due to some tasks sets not being able to be scheduled by G-EDF that other more advanced algorithms would simply get through. Due to these cases, G-EDF is still cursed to be a task scheduler that works better on uniprocessors than multi-core processors [8-10]. 

## Hybrid Scheduling

As the name suggests, hybrid scheduling combines multiple scheduling types to use the power of each of them to their advantage. Most commonly, it leverages a combination of both global and partitioning scheduling to its advantage with the hopes that both migration and a lack of migration can make a best-of-both-worlds solution.

The main benefit of global scheduling comes with its power of task migration to move processes between different cores, which can help improve load balancing. However, task migration leads to a high amount of overhead to can lead to problems when it comes to hitting real-time deadlines. Using partitioned scheduling allows a processor to reduce overhead by not allowing a task to remove, which reduces overhead caused by task migration. Swapping between the two variations of scheduling allows a system to dynamically give another level of priority to a certain task that has a real-time deadline over a less important task that can be accomplished later. Figure 2 shows hybrid scheduling used in a warehouse scenario:

![[Schematic-diagram-of-the-hybrid-scheduling-mechanism.png | center]]
<center> <b> Figure 2: </b> Schematic Diagram of the Hybrid Scheduling Mechanism [11] </center>

When compared to RMS and EDF, this is a major step towards a multi-core solution. Since RMS and EDF typically do not even have the power to move processes between cores, a hybrid approach builds on top of the lightweight uniprocessing schedulers and allows better system utilization while providing the real-time guarantees that a system may need to hit. This type of approach would be best set for a more common-day system that needs to take advantage of multi-core processing, but does not miss hitting deadlines for tasks that might put the system at a standstill [8-9, 11].

## Slack Stealing

Even for higher priority tasks, there are often opportunities where it finishes it’s process before it’s allotted execution time. The time in-between is often not utilized by more simple task schedulers, like RMS and EDF, which can lead to a lower processor usage. In the worst case, this lack of usage could affect multiple cores at once and make the processor crawl to a snail’s pace as multiple high-priority processes are all holding onto possible execution points. To mitigate this, the concept of a slack stealing scheduler has been developed. As the name suggests, it allows a lower-priority tasks to migrate over a higher-priority task if it is idle.

The overall idea for stack stealing seems simple, but it is an effective tool to improve the utilization of a multi-core system. More importantly, it does not impede on the real-time demands that might be set by a higher-priority task as it only steals the execution block if the higher-priority task finishes earlier than expected. This makes it such that the priority hierarchy of processors is upheld while making sure the processor is not left idle for when it could be running. RMS can be especially guilty of not sharing a core as it allows a higher-priority process to run as long as it is not fully finished, leading to a poor utilization usage and possible deadline misses. Figure 3 below illustrates how the slack is calculated as a higher-priority task is finalized:

![[Pasted image 20250318195746.png | center]]
<center> <b> Figure 3: </b> How the Slack at Each Level is Calculated as a Task Finishes [12] </center>

However, there are still concerns with an inefficient process that will not report it’s slack time. For example, if a cache-miss or an IO event is not handled right with interrupts or pausing, a higher-priority process might hold on to it’s allotted time for as long as it wants if it is not implemented with slack stealing in mind. Even though it might not affect the timing of the processes directly, there is a decent amount of overhead that must be added to trigger a task migration to the next highest-priority task in queue after a high-priority task finishes before it was expected to [8-9, 12].

## Fair Scheduling

Unlike the few previous examples of task scheduling that focuses to maximize the effectiveness of how task migration is used, fair scheduling aims to effectively utilize a system’s resources. Specifically, it aims to fairly divide them among each task such that one task is not struggling to complete due to a lack of resources. The way fairness is enforced often falls into two primary methods: **proportional fairness** and **max-min fairness**.

Proportional fairness gives weights to each process based on a multitude of factors, which determine how much resources a task is given in proportion to another. For instance, if Task A has a weight of `2` and Task B has a weight of `1`, Task A should be given twice as much CPU time as Task B. The most interesting part about this approach is that weights can either be tied directly to priority or can have multiple considerations. This allows a multiple-variable correlation between priority and resource usage. Higher-priority tasks can be given a small amount of the CPU if they are not resource intensive and low-priority tasks can be given more resources if they need it. Figure 4 below illustrates an example of how a Linux distribution decides weights in the form of a red-black tree. Note that the number is backwards for this implementation with the lower number representing a higher weight.

![[figure1.gif | center]]
<center> <b> Figure 4: </b> Red-Black Tree of Weights for Processes on the Linux Kernel [13] </center>

Max-min fairness, on the other hand, tries to mitigate the issue of shared resources by minimizing the amount of processes that are sharing the resources at the same time. This no only ensures that a task will not be starved of resources, it prevent deadlocks from happening as ideally two processes will not fight over the same resource whenever possible.

Both of these variations are improvements over both RMS and EDF as neither of them take resource management into consideration. This improved resource management leads to a much improved multi-core performance as it can effectively balance loads across multiple cores while also considering conflicting resource calls between processes [8-9, 13].
## Cluster Scheduling

**Cluster scheduling** is a strategy used in multiprocessor systems to balance the trade-off between task migration overhead and system flexibility. Unlike global scheduling, where tasks can migrate freely across all processors, cluster scheduling groups processors into clusters and restricts task migration to within these clusters. This approach aims to reduce the overhead associated with frequent task migrations while still allowing some degree of flexibility in task allocation.

The primary goal of cluster scheduling is to effectively utilize system resources by dividing the system into smaller, manageable units (clusters). Each cluster contains a subset of processors, and tasks assigned to a cluster can migrate between the processors within that cluster. However, tasks cannot migrate between clusters, which limits the scope of migration and reduces the associated overhead. This structure allows for better load balancing within clusters while maintaining a more controlled and predictable system behavior compared to fully global scheduling. Figure 5 below illustrates how the clustering algorithm breaks tasks down:

![[The-cluster-scheduling-architecture.jpg | center]]
<center> <b> Figure 5: </b> Red-Black Tree of Weights for Processes on the Linux Kernel [14] </center>

One of the key advantages of cluster scheduling is its ability to minimize migration overhead. In global scheduling, tasks can migrate across all processors, which can lead to significant overhead due to context switching and cache inefficiencies. By restricting migration to within clusters, cluster scheduling reduces this overhead, making it more suitable for systems with a large number of processors. Additionally, cluster scheduling can improve scalability by dividing the system into smaller, independent units, each of which can be managed more efficiently.

However, cluster scheduling is not without its challenges. One potential issue is load imbalance between clusters. Since tasks cannot migrate between clusters, it is possible for one cluster to become overloaded while another cluster has idle processors. To mitigate this, cluster scheduling often involves careful task assignment to clusters, ensuring that workloads are evenly distributed across the system. This can be achieved through static assignment based on task characteristics or dynamic reassignment as workloads change.

In comparison to other scheduling strategies like RMS and EDF, cluster scheduling offers a more balanced approach to resource management. While RMS and EDF focus primarily on task priorities and deadlines, cluster scheduling takes into account the physical constraints of the system, such as the cost of task migration and the need for load balancing across multiple processors. This makes cluster scheduling particularly well-suited for multi-core systems, where the goal is to maximize resource utilization while minimizing overhead [8-9, 14].

# Real-World Scenarios

Most of the discussion up to this point has focused on theoretical time saves that these algorithms provide. However, there are many cases where these algorithms are used that do provide improved processor utilization for real-time systems. In particular, there were two studies that are most interesting: one focuses on implementing a Zero-Slack policy on automotive safety systems and dynamic reclaiming algorithm (DRA) with dynamic voltage and frequency scaling (DVFS) to create a hybrid solution for industrial automation control systems.

## Case Study 1: Automotive Safety Systems & The Zero-Slack Scheduler [15]

The first case study was conducted by Carnegie Mellon University researchers as they saw a problem with the current implementation of safety systems in modern cars at the time. They define these type of systems are mixed-criticality systems as the car will continue with it’s lower priority tasks and then sudden release a large burst of high-criticality tasks in the case of an emergency, such as a crash or the ani-lock braking system (ABS) initiating on a slippery stop. They found that worst execution time for processes are incorrectly calculated and can often lead to issues where medium-critical tasks might be blocked by another process if they are waiting for execution. In transportation, even a small amount of time saved can be the difference between life and death. For example, the ABS might fail to engage fast enough if the car deploys it’s air bags, which can cause the car to slip further into danger. Therefore, they proposed a zero-slack task scheduler that tries to allow as many real-time tasks to be executed before their deadline in such a complicated system. To test their new system, they implemented their Zero-Slack system on a Linux/RK operating system that runs real-world automotive control systems. With the ABS, vehicle navigation systems, infotainment systems, and more wired up, they compared their variation to the traditional RMS and EDF systems. Table 1 below summarizes the difference between RMS/EDF and the proposed Zero-Slack algorithm:

| Aspect                     | Traditional (RMS/EDF)                            | Modern (Zero-Slack)                                    |
| -------------------------- | ------------------------------------------------ | ------------------------------------------------------ |
| **WCET Handling**          | Conservative estimates leading to poor uilizaion | Dynamic adjustment based on actual execution time      |
| **Criticality Management** | Binary priority assignment                       | Multiple criticality levels with asymmetric protection |
| **Resource Utilization**   | Reserved for worst-case                          | Adaptive allocation based on actual demands            |
| **Deadline Guaranetees**   | Fixed priorities                                 | Guaranteed protection for higher-criticality tasks     |

<center> <b> Table 1: </b> Key Differences Between Traditional Methods and the Zero-Slack Scheduler [15] </center>

When it came to the results of the algorithm, the Zero-Slack algorithm destroyed metrics over the traditional RMS/EDF system. Zero-Slack consistently utilizes around 85% of the CPU at all times, while RMS/EDF consistently fell to the worst-case times with only 60% utilization. Zero-Slack also saw a great improvement in deadline miss rate where it had a near-zero miss rate on important tasks, while RMS/EDF would sometimes miss the deadline of these tasks. When compared to RMS/EDF, this modern scheduler is designed to handle complex criticalities where just a priority value will not suffice. The Zero-Slack scheduler avoids over-reserving processor resources and hits deadlines that would otherwise be impossible with the traditional RMS/EDF approach. It also improves on scalability as it allows for mixed-criticality systems which allows for more processes to be spread over more cores without as many problems.

## Case Study 2: Real-Time Schedulers using DVFS for Industrial Automation Control Systems [16]

A few years after the group at Carnegie Mellon published their paper, researchers at Virginia Tech issued a new variation of a scheduler called Real-Time Dynamic Voltage and Frequency Scaling (RT-DVFS) . As the name suggests, this algorithm allows for the scheduler to dynamically allocate a different amount of voltage or give a different clock rate to a lower-priority or resource-intensive process to save power. In the case study, they describe fourteen variations that build DVFS into common schedulers like EDF and Dynamic Reclaiming Algorithm (DRA) to see if their resource consumption and process utilization improved. All these algorithms were implemented using a modified version of the ChronOS Linux kernel on a medium-specification computer that was meant to simulate an industrial controller. 

After comparing the traditional methods’ (RMS/EDF) power management to the ones provided by DVFS, the differences are astounding. Static EDF provided an active power of 25W and an idle power of 1W, while DVFS gave a range between 11.25W and 25W for active power and anywhere from 0.3W-1W for idle power. When given a light workload (30% usage), static-EDF showed a power consumption of 93.5%, while DRA-DVFS was able to drop the power consumption down to 87.2%. As the load increases o a 90% core usage, DVFS increases it’s power to 89% power consumption in order to compensate for the higher load. Not only that, it implements variable workloads by giving processor usage dynamically through it’s variable power and frequency and provides real-time guarantees by pushing for power awareness in the architecture. For these reasons, this more modern scheduler works significantly better over RMS/EDF as it shows significant gains in resource utilization while maintaining safety guarantees.

# Conclusion

The shift from single-core to multi-core processors has exposed the limitations of traditional real-time scheduling algorithms like Rate Monotonic Scheduling (RMS) and Earliest Deadline First (EDF). While effective in single-core environments, RMS and EDF struggle with task migration, load balancing, synchronization overhead, scalability, shared resource contention, dynamic workloads, and energy efficiency in multi-core systems. These shortcomings have led to the development of advanced scheduling techniques such as Global Earliest Deadline First (G-EDF), hybrid scheduling, slack stealing, fair scheduling, and cluster scheduling. Each method addresses specific challenges, offering improvements in CPU utilization, deadline adherence, and resource management, making them better suited for modern multi-core systems.

Real-world applications, such as the Zero-Slack scheduler in automotive safety systems and Dynamic Voltage and Frequency Scaling (DVFS) in industrial automation, demonstrate the practical advantages of these advanced techniques. These implementations show significant gains in CPU utilization, energy efficiency, and real-time performance compared to traditional RMS and EDF approaches. As multi-core processors continue to evolve, further innovation in real-time scheduling will be essential to meet the growing demands of complex, dynamic, and resource-intensive applications, ensuring optimal performance and scalability in future systems.

# Resources

[1] M. Wolf, _Computers as Components: Principles of Embedded Computing System Design_. Cambridge, MA: Elsevier/Morgan Kaufmann, 2023.
[2] Z. Deng _et al._, “Interference-Free Operating System: A 6 years’ Experience in Mitigating Cross-Core Interference in Linux,” _2024 IEEE Real-Time Systems Symposium (RTSS)_, pp. 308–321, Dec. 2024. doi:10.1109/rtss62706.2024.00034
[3] R. Sharma and N. Nitin, “Task migration with EDF-RM scheduling algorithms in Distributed System,” _2012 International Conference on Advances in Computing and Communications_, pp. 182–185, Aug. 2012. doi:10.1109/icacc.2012.42
[4]  S. Jadon et al., “A comprehensive study of load balancing approaches in real-time multi-core systems for mixed real-time tasks,” IEEE Access, vol. 12, pp. 53373–53395, 2024. doi:10.1109/access.2024.3388291 
[5] M. R. Nahin and S. R. Ahmed, “A comprehensive study of OS strategies and New Scheduling Techniques,” _International Journal of Computer Applications_, vol. 186, no. 62, pp. 11–19, Jan. 2025. doi:10.5120/ijca2025924424
[6] M. Dellinger, A. Lindsay, and B. Ravindran, “An Experimental Evaluation of the Scalability of Real-Time Scheduling Algorithms on Large-Scale Multicore Platforms,” _ACM Journal of Experimental Algorithmics_, vol. 17, Jul. 2012. doi:10.1145/2133803.2345677
[7] ScienceDirect, “Priority Inversion,” ScienceDirect Topics, https://www.sciencedirect.com/topics/computer-science/priority-inversion
[8] S. Alirezazadeh and L. A. Alexandre, “A Survey on Task Allocation and Scheduling in Robotic Network Systems,” _IEEE Internet of Things Journal_, vol. 12, no. 2, pp. 1484–1508, Jan. 2025. doi:10.1109/jiot.2024.3491944
[9] J. Erickson and J. Anderson, “Beating G-EDF at its Own Game: New Results on G-EDF-like Schedulers,” University of North Carolina, https://www.cs.unc.edu/~anderson/papers/rtss11a.pdf
[10] K. Boukir, J.-L. Béchennec, and A.-M. Déplanche, “Requirement Specification and Model-Checking of a Real-Time Scheduler Implementation,” _Proceedings of the 28th International Conference on Real-Time Networks and Systems_, pp. 89–99, Jun. 2020. doi:10.1145/3394810.3394817
[11] G. Fan and Z. Jiang, “Hybrid scheduling method for automatic guided vehicles in intelligent warehouses considering power management,” _The International Journal of Advanced Manufacturing Technology_, vol. 130, no. 7–8, pp. 3685–3695, Jan. 2024. doi:10.1007/s00170-023-12900-1
[12] J. M. Urriza, J. D. Orozco, and R. Cayssials, "Fast Slack Stealing methods for Embedded Real Time Systems," *26th IEEE International Real-Time Systems Symposium (RTSS 2005)*, Miami, EEUU, 2005.
[13] M. Jones, “Inside the Linux 2.6 Completely Fair Scheduler,” IBM Developer, https://developer.ibm.com/tutorials/l-completely-fair-scheduler/
[14] S. Ejaz *et al.*, “A secure operating system for Data Centers: A survey,” _International Journal of ADVANCED AND APPLIED SCIENCES_, vol. 7, no. 8, pp. 53–64, Aug. 2020. doi:10.21833/ijaas.2020.08.007
[15] D. de Niz, K. Lakshmanan, and R. Rajkumar, “On the scheduling of mixed-criticality real-time task sets,” _2009 30th IEEE Real-Time Systems Symposium_, pp. 291–300, Dec. 2009. doi:10.1109/rtss.2009.46
[16] S. Saha and B. Ravindran, “An Experimental Evaluation of Real-Time DVFS Scheduling Algorithms,” _Proceedings of the 5th Annual International Systems and Storage Conference_, pp. 1–12, Jun. 2012. doi:10.1145/2367589.2367604