Date: 8th May 2025
Date Modified: 8th May 2025
File Folder: Kanban
## Publication Information

**Database:** Social Science Research Network

**DOI**: https://drive.google.com/file/d/1NQxedDpuC4ZXz7wPmhHAs-r9VfQiAb8P/view

**Authors**: Béatrice Schütte, Lotta Majewski, Katri Havu

**Publication Year**: 2021

**Country of Study**: Finland

**Tags**: 

```ad-abstract
title: Abstract
collapse: open
Artificial intelligence (AI) is an integral part of our everyday lives, able to perform a multitude of tasks with little to no human intervention. Many legal issues related to this phenomenon have not been comprehensively resolved yet. In that context, the question arises whether the existing legal rules on damages liability are sufficient for resolving cases involving AI. The EU institutions have started evaluating if and to what extent new legislation regarding AI is needed, envisioning a European approach to avoid fragmentation of the Single Market.
This article critically analyses the most relevant preparatory documents and proposals with
regard to civil liability for AI issued by EU legislators. In addition, we discuss the adequacy of
existing legal doctrines on private liability in terms of resolving cases where AI is involved.
While existing national laws on damages liability can be applied to AI-related harm, the risk
exists that case outcomes are unpredictable and divergent, or, in some instances, unjust. The
envisioned level playing field throughout the Single Market justifies harmonisation of many
aspects of damages liability for AI-related harm. In the process, particular AI characteristics
should be carefully considered in terms of questions such as causation and burden of proof.
```

**Embed to Paper**: ![[AILiaEU in Flux SSRN 8_21.pdf]]

## Summary

### **I. Introduction**

- AI performs complex tasks independently and is increasingly pervasive in everyday life.
    
- Legal issues around **liability for AI-caused harm** (e.g., injuries from robots, smart devices) remain unresolved.
    
- Traditional fault-based liability frameworks struggle with the **autonomy and opaqueness** of AI.
    
- Existing laws may produce **inconsistent or unjust outcomes**, justifying **EU-level harmonization**.
    

---

### **II. Plans for Developing EU Law**

#### A. European Commission Initiatives

##### (i) White Paper on AI

- Proposes a **risk-based approach** to AI regulation:
    
    - High-risk sectors (healthcare, transport)
        
    - High-impact usage
        
- Responsibility should fall on the actor **most capable of risk control**.
    
- AI providers, even if non-EU-based, should fall under EU law if they serve the EU market.
    

##### (ii) Safety and Liability Report

- Notes difficulty in identifying liable actors in **complex IoT-AI ecosystems**.
    
- Suggests **strict liability and insurance-based solutions**, similar to car insurance schemes.
    

##### (iii) Draft AI Act (2021)

- Focuses on governance, standards, and risk classification.
    
- Proposes **supervision, sandbox testing, and monitoring**, but **does not create civil liability rules**.
    

#### B. European Parliament Resolutions

##### (i) 2020 Civil Liability Resolution

- Proposes harmonized AI operator liability.
    
- Defines AI broadly as autonomous, goal-driven software or hardware.
    
- Recommends **joint and several liability** for multiple operators.
    

##### (ii) Draft Report and JURI Study

- Recommends **strict liability for high-risk AI**.
    
- Suggests monitoring by expert bodies, and **targeted regulation** based on who controls the risk.
    
- Rejects giving AI legal personality.
    

---

### **III. Existing and Planned EU Rules Addressing Specific Liability Contexts**

#### A. Product Liability (PLD) and Product Safety

- PLD imposes **no-fault liability** for defective products.
    
- Challenges for AI:
    
    - Defining **product**, **defect**, and **damage**
        
    - Excludes **pure economic and non-material harm**
        
- Victims face **high burden of proof**, especially for causation.
    

#### B. GDPR (General Data Protection Regulation)

- Article 82: Data subjects can claim **material or non-material damages**.
    
- Controllers/processors are liable unless they prove no fault.
    
- Burden-shifting and collective redress mechanisms apply.
    
- National divergence still exists in how GDPR liability is applied.
    

#### C. Digital Services Act

- Proposes modern rules for **platform liability**, especially for **AI-powered content moderation**.
    
- Liability still largely governed by **national laws**.
    

#### D. Medical Devices Regulation (MDR)

- Applies to **AI software as medical devices**.
    
- Introduces **mandatory insurance and safety standards**.
    
- Higher safety expectations justified by **CJEU rulings** (e.g., for pacemakers).
    

---

### **IV. National Developments in Member States**

#### A. Germany

- Updated **Road Traffic Act** to allow Level 3–5 automation.
    
- Maintains **strict liability** for vehicle keepers and fault-based driver liability.
    

#### B. Austria

- Draft rules suggest **technical tools = human agents** for liability.
    
- Criticized for lacking clarity on defining machine “misconduct.”
    

#### C. Finland

- Concerned with **administrative AI** (e.g., automated public decision-making).
    
- Emphasis on **public office accountability** over individual blame.
    

#### D. Estonia

- Recommends placing risk on the **beneficiary of AI use**.
    
- Advocates reviewing **burden of proof** and supports **AI-friendly policies**.
    

---

### **V. Discussion**

#### A. Substantive Challenges in AI Liability

##### (i) Identifying Liable Parties

- Complex value chains obscure liability.
    
- Legal personhood for AI is **rejected**.
    
- Main models:
    
    - **Producer liability**
        
    - **Operator/user liability**
        
    - **Vicarious liability** (analogous to employer-employee relationships)
        

##### (ii) Causation

- AI's **autonomy and opacity** break traditional causal chains.
    
- **‘Foreseeability’** becomes ambiguous in self-learning systems.
    
- Some propose **‘logging by design’** to trace decisions.
    

##### (iii) Fault

- Intention/negligence is hard to prove with opaque systems.
    
- Courts may need to shift toward **objective technical standards**.
    

##### (iv) Nature of Harm

- AI often causes **non-material or economic loss**, traditionally **non-compensable**.
    
- **EU law requires** recovery where EU rights are violated (e.g., GDPR).
    
- Harmonization needed to clarify **recoverable harms**.
    

##### (v) Interim Conclusion

- Current laws **create uncertainty** and may **fail to protect** victims of AI harm.
    
- Calls for **clearer rules on fault, causation, and liability attribution**.
    

#### B. Future Path for EU Law

- Options include:
    
    - **Amending the PLD**
        
    - **New EU civil liability regulation**
        
    - **Targeted reforms for high-risk AI**
        
- **Strict liability plus insurance** is a leading model.
    
- Need to balance **innovation incentives** and **user protection**.
    

---

### **VI. Conclusion**

- The growing use of AI in high-stakes decisions makes **predictable, fair, and harmonized liability rules** a priority.
    
- National responses are diverging; without EU-level action, the **Single Market risks fragmentation**.
    
- EU initiatives like the **AI Act** and **GDPR** offer a partial foundation, but **civil liability gaps remain**.
    
- A carefully crafted EU liability regime is needed to promote both **technological innovation** and **legal certainty**.
    

---
