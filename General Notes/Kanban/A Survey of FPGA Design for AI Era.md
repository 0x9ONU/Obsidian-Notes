Date: 8th May 2025
Date Modified: 8th May 2025
File Folder: Kanban
## Publication Information

**Database:** COMSOL

**DOI**: https://iopscience.iop.org/article/10.1088/1674-4926/41/2/021402/pdf

**Authors**: Zhengjie Li, Yufan Zhang, Jian Wang, and Jinmei Lai

**Publication Year**: 2020

**Country of Study**: China

**Tags**: #hwsw #applications #architecture #ai #fpga #DNN #dsp #CLB #ALM

```ad-abstract
title: Abstract
collapse: open
FPGA is an appealing platform to accelerate DNN. We survey a range of FPGA chip designs for AI. For DSP module,
one type of design is to support low-precision operation, such as 9-bit or 4-bit multiplication. The other type of design of DSP
is to support floating point multiply-accumulates (MACs), which guarantee high-accuracy of DNN. For ALM (adaptive logic mod-
ule) module, one type of design is to support low-precision MACs, three modifications of ALM includes extra carry chain, or 4-
bit adder, or shadow multipliers which increase the density of on-chip MAC operation. The other enhancement of ALM or CLB
(configurable logic block) is to support BNN (binarized neural network) which is ultra-reduced precision version of DNN. For
memory modules which can store weights and activations of DNN, three types of memory are proposed which are embedded
memory, in-package HBM (high bandwidth memory) and off-chip memory interfaces, such as DDR4/5. Other designs are new ar-
chitecture and specialized AI engine. Xilinx ACAP in 7 nm is the first industry adaptive compute acceleration platform. Its AI en-
gine can provide up to 8X silicon compute density. Intel AgileX in 10 nm works coherently with Intel own CPU, which increase
computation performance, reduced overhead and latency.
```

**Embed to Paper**: ![[A Survey of FPGA Design for AI Era.pdf]]

## Summary

### Introduction

### DSP module design for AI

### ALM/CLB module design for AI

### Memory module design for AI

### Other designs for AI

